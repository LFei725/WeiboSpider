# 新浪微博爬虫

## 支持通过关键词爬取微博及其相关内容

爬取地址：新浪微博手机端  https://m.weibo.cn/

两个py文件分别为：

#### Weibo&comments_spider

爬取关键词对应的微博信息及其评论信息，可获取内容如下：

```
('关键词', '微博链接', '博主id', '博主昵称', '博主账号等级', '博主性别',
'发博日期', '发博时间', '微博内容', '转发量', '评论量', '点赞量',
'评论者id', '评论者昵称', '评论者账号等级', '评论者性别', '评论日期', '评论时间', '评论内容', '点赞数')
```

#### Only_weibo_spider

仅爬取关键词对应的微博信息及发博人相关信息，可获取的内容如下：

```
('关键词', '微博链接', '博主id', '博主昵称', '博主账号等级', '博主性别',
                 '发博日期', '发博时间', '微博内容', '转发量', '评论量', '点赞量')
```



### 使用方法

在每个文件最下方main函数里的关键词表中输入想要爬取的关键词，然后运行文件即可。

```
if __name__ == '__main__':
    # 待搜索关键词
    title_list = ['双减', '三胎']  # 可以输入多个关键词
```



爬下来的数据会以csv的形式存储

